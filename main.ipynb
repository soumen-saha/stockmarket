{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + Importing the data\n",
    "# + Cleaning the data\n",
    "# + Splitting the data into Training/Test sets\n",
    "#   Create a model\n",
    "#   Train the model\n",
    "#   Make Predictions\n",
    "#   Evaluate and Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1215.000000  1215.000000  1215.000000  1215.000000  1215.000000   \n",
       "mean   6453.332599  6490.039058  6407.286790  6448.411360  6448.411360   \n",
       "std    1261.376255  1262.418721  1256.469595  1259.101220  1259.101220   \n",
       "min    4623.149902  4623.149902  4531.149902  4544.200195  4544.200195   \n",
       "25%    5456.375000  5499.375000  5408.400147  5452.824951  5452.824951   \n",
       "50%    5943.149902  5972.700195  5910.799805  5938.799805  5938.799805   \n",
       "75%    7828.475098  7867.375000  7763.199951  7815.300049  7815.300049   \n",
       "max    9109.150391  9119.200195  8925.549805  8996.250000  8996.250000   \n",
       "\n",
       "              Volume  \n",
       "count    1215.000000  \n",
       "mean    96222.962963  \n",
       "std     88030.479826  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%    122200.000000  \n",
       "75%    159000.000000  \n",
       "max    437000.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1215.000000</td>\n      <td>1215.000000</td>\n      <td>1215.000000</td>\n      <td>1215.000000</td>\n      <td>1215.000000</td>\n      <td>1215.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6453.332599</td>\n      <td>6490.039058</td>\n      <td>6407.286790</td>\n      <td>6448.411360</td>\n      <td>6448.411360</td>\n      <td>96222.962963</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1261.376255</td>\n      <td>1262.418721</td>\n      <td>1256.469595</td>\n      <td>1259.101220</td>\n      <td>1259.101220</td>\n      <td>88030.479826</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4623.149902</td>\n      <td>4623.149902</td>\n      <td>4531.149902</td>\n      <td>4544.200195</td>\n      <td>4544.200195</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5456.375000</td>\n      <td>5499.375000</td>\n      <td>5408.400147</td>\n      <td>5452.824951</td>\n      <td>5452.824951</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5943.149902</td>\n      <td>5972.700195</td>\n      <td>5910.799805</td>\n      <td>5938.799805</td>\n      <td>5938.799805</td>\n      <td>122200.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7828.475098</td>\n      <td>7867.375000</td>\n      <td>7763.199951</td>\n      <td>7815.300049</td>\n      <td>7815.300049</td>\n      <td>159000.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9109.150391</td>\n      <td>9119.200195</td>\n      <td>8925.549805</td>\n      <td>8996.250000</td>\n      <td>8996.250000</td>\n      <td>437000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# + Importing the Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fileName = 'stock-market-data-5y.csv'\n",
    "\n",
    "df = pd.read_csv(fileName)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1234, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1234,)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# + Cleaning the Data\n",
    "\n",
    "df1 = df.reset_index()['Close']\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a744b4b760>]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 381.65 248.518125\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-12T06:25:35.413533</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 248.518125 \r\nL 381.65 248.518125 \r\nL 381.65 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 39.65 224.64 \r\nL 374.45 224.64 \r\nL 374.45 7.2 \r\nL 39.65 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mfc0476c8f3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.868182\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(51.686932 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"104.23779\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(94.69404 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"153.607399\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 400 -->\r\n      <g transform=\"translate(144.063649 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-34\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"202.977007\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 600 -->\r\n      <g transform=\"translate(193.433257 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2113 2584 \r\nQ 1688 2584 1439 2293 \r\nQ 1191 2003 1191 1497 \r\nQ 1191 994 1439 701 \r\nQ 1688 409 2113 409 \r\nQ 2538 409 2786 701 \r\nQ 3034 994 3034 1497 \r\nQ 3034 2003 2786 2293 \r\nQ 2538 2584 2113 2584 \r\nz\r\nM 3366 4563 \r\nL 3366 3988 \r\nQ 3128 4100 2886 4159 \r\nQ 2644 4219 2406 4219 \r\nQ 1781 4219 1451 3797 \r\nQ 1122 3375 1075 2522 \r\nQ 1259 2794 1537 2939 \r\nQ 1816 3084 2150 3084 \r\nQ 2853 3084 3261 2657 \r\nQ 3669 2231 3669 1497 \r\nQ 3669 778 3244 343 \r\nQ 2819 -91 2113 -91 \r\nQ 1303 -91 875 529 \r\nQ 447 1150 447 2328 \r\nQ 447 3434 972 4092 \r\nQ 1497 4750 2381 4750 \r\nQ 2619 4750 2861 4703 \r\nQ 3103 4656 3366 4563 \r\nz\r\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-36\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"252.346616\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 800 -->\r\n      <g transform=\"translate(242.802866 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 2216 \r\nQ 1584 2216 1326 1975 \r\nQ 1069 1734 1069 1313 \r\nQ 1069 891 1326 650 \r\nQ 1584 409 2034 409 \r\nQ 2484 409 2743 651 \r\nQ 3003 894 3003 1313 \r\nQ 3003 1734 2745 1975 \r\nQ 2488 2216 2034 2216 \r\nz\r\nM 1403 2484 \r\nQ 997 2584 770 2862 \r\nQ 544 3141 544 3541 \r\nQ 544 4100 942 4425 \r\nQ 1341 4750 2034 4750 \r\nQ 2731 4750 3128 4425 \r\nQ 3525 4100 3525 3541 \r\nQ 3525 3141 3298 2862 \r\nQ 3072 2584 2669 2484 \r\nQ 3125 2378 3379 2068 \r\nQ 3634 1759 3634 1313 \r\nQ 3634 634 3220 271 \r\nQ 2806 -91 2034 -91 \r\nQ 1263 -91 848 271 \r\nQ 434 634 434 1313 \r\nQ 434 1759 690 2068 \r\nQ 947 2378 1403 2484 \r\nz\r\nM 1172 3481 \r\nQ 1172 3119 1398 2916 \r\nQ 1625 2713 2034 2713 \r\nQ 2441 2713 2670 2916 \r\nQ 2900 3119 2900 3481 \r\nQ 2900 3844 2670 4047 \r\nQ 2441 4250 2034 4250 \r\nQ 1625 4250 1398 4047 \r\nQ 1172 3844 1172 3481 \r\nz\r\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-38\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"301.716224\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 1000 -->\r\n      <g transform=\"translate(288.991224 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.085833\" xlink:href=\"#mfc0476c8f3\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 1200 -->\r\n      <g transform=\"translate(338.360833 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0968b5cd22\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0968b5cd22\" y=\"194.518677\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5000 -->\r\n      <g transform=\"translate(7.2 198.317895)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0968b5cd22\" y=\"150.118291\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 6000 -->\r\n      <g transform=\"translate(7.2 153.91751)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-36\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0968b5cd22\" y=\"105.717906\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 7000 -->\r\n      <g transform=\"translate(7.2 109.517125)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 525 4666 \r\nL 3525 4666 \r\nL 3525 4397 \r\nL 1831 0 \r\nL 1172 0 \r\nL 2766 4134 \r\nL 525 4134 \r\nL 525 4666 \r\nz\r\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-37\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0968b5cd22\" y=\"61.31752\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 8000 -->\r\n      <g transform=\"translate(7.2 65.116739)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-38\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0968b5cd22\" y=\"16.917135\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 9000 -->\r\n      <g transform=\"translate(7.2 20.716354)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 703 97 \r\nL 703 672 \r\nQ 941 559 1184 500 \r\nQ 1428 441 1663 441 \r\nQ 2288 441 2617 861 \r\nQ 2947 1281 2994 2138 \r\nQ 2813 1869 2534 1725 \r\nQ 2256 1581 1919 1581 \r\nQ 1219 1581 811 2004 \r\nQ 403 2428 403 3163 \r\nQ 403 3881 828 4315 \r\nQ 1253 4750 1959 4750 \r\nQ 2769 4750 3195 4129 \r\nQ 3622 3509 3622 2328 \r\nQ 3622 1225 3098 567 \r\nQ 2575 -91 1691 -91 \r\nQ 1453 -91 1209 -44 \r\nQ 966 3 703 97 \r\nz\r\nM 1959 2075 \r\nQ 2384 2075 2632 2365 \r\nQ 2881 2656 2881 3163 \r\nQ 2881 3666 2632 3958 \r\nQ 2384 4250 1959 4250 \r\nQ 1534 4250 1286 3958 \r\nQ 1038 3666 1038 3163 \r\nQ 1038 2656 1286 2365 \r\nQ 1534 2075 1959 2075 \r\nz\r\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-39\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p4b58569966)\" d=\"M 54.868182 143.120786 \r\nL 55.11503 143.62029 \r\nL 55.361878 146.575149 \r\nL 55.608726 147.975973 \r\nL 56.102422 160.647838 \r\nL 56.34927 161.036342 \r\nL 56.596118 156.190044 \r\nL 57.089814 165.456413 \r\nL 57.336662 165.447524 \r\nL 57.58351 162.370586 \r\nL 57.830358 163.835799 \r\nL 58.077206 162.923358 \r\nL 58.324054 163.593808 \r\nL 58.570902 161.51809 \r\nL 58.81775 163.997856 \r\nL 59.311447 171.779024 \r\nL 59.558295 172.056526 \r\nL 59.805143 175.994827 \r\nL 60.051991 175.33771 \r\nL 60.298839 171.130774 \r\nL 60.545687 176.947224 \r\nL 60.792535 176.936124 \r\nL 61.286231 183.260968 \r\nL 61.533079 184.493078 \r\nL 61.779927 180.754557 \r\nL 62.026775 174.272101 \r\nL 62.273623 173.162091 \r\nL 62.520471 173.131002 \r\nL 62.767319 170.256077 \r\nL 63.014167 174.141111 \r\nL 63.261015 171.492632 \r\nL 63.754711 175.100164 \r\nL 64.001559 182.854687 \r\nL 64.495255 179.722248 \r\nL 64.742104 171.328364 \r\nL 64.988952 170.711181 \r\nL 65.2358 170.597969 \r\nL 65.482648 173.954642 \r\nL 65.729496 171.394965 \r\nL 65.976344 170.942072 \r\nL 66.47004 174.740516 \r\nL 66.716888 170.919872 \r\nL 66.963736 174.554048 \r\nL 67.210584 171.823424 \r\nL 67.70428 177.926244 \r\nL 67.951128 178.323636 \r\nL 68.691672 171.32392 \r\nL 68.93852 165.469724 \r\nL 69.185368 164.004512 \r\nL 69.925912 157.499855 \r\nL 70.17276 157.841747 \r\nL 70.419608 154.183138 \r\nL 70.666457 154.112115 \r\nL 70.913305 154.924633 \r\nL 71.160153 155.193247 \r\nL 71.653849 159.633285 \r\nL 71.900697 154.047725 \r\nL 72.394393 162.146351 \r\nL 72.641241 161.629091 \r\nL 72.888089 156.705093 \r\nL 73.134937 155.237647 \r\nL 73.628633 155.961386 \r\nL 74.369177 161.240588 \r\nL 74.616025 163.380695 \r\nL 74.862873 169.421359 \r\nL 75.109721 170.669014 \r\nL 75.356569 174.101155 \r\nL 75.603417 170.034075 \r\nL 75.850265 170.04962 \r\nL 76.097113 170.486968 \r\nL 76.343962 169.430247 \r\nL 76.59081 172.933434 \r\nL 76.837658 170.331567 \r\nL 77.578202 175.84387 \r\nL 77.82505 175.510867 \r\nL 78.071898 172.924545 \r\nL 78.318746 177.355716 \r\nL 78.565594 176.98718 \r\nL 78.812442 179.025153 \r\nL 79.306138 173.379649 \r\nL 79.552986 173.51285 \r\nM 80.046682 168.233648 \r\nL 80.540378 171.574777 \r\nL 80.787226 170.89546 \r\nL 81.034074 169.825407 \r\nL 81.280922 171.126329 \r\nL 81.52777 171.383864 \r\nL 81.774618 172.948978 \r\nL 82.021466 173.082179 \r\nL 82.268315 172.296284 \r\nL 82.762011 176.902824 \r\nL 83.008859 178.25038 \r\nL 83.255707 183.067822 \r\nL 83.502555 182.270826 \r\nL 83.749403 182.162058 \r\nL 83.996251 180.310553 \r\nL 84.243099 173.594995 \r\nL 84.489947 171.137429 \r\nL 84.736795 170.307155 \r\nL 85.230491 165.773871 \r\nL 85.477339 166.670746 \r\nL 85.724187 165.636226 \r\nL 85.971035 166.453189 \r\nL 86.217883 166.748447 \r\nL 86.464731 162.153007 \r\nL 87.205275 171.157418 \r\nL 87.452123 168.524462 \r\nL 87.698971 171.772368 \r\nL 87.94582 168.717608 \r\nL 88.192668 169.341447 \r\nL 88.439516 167.276829 \r\nL 88.933212 170.471424 \r\nL 89.18006 166.371044 \r\nL 89.426908 164.313103 \r\nL 89.673756 168.995111 \r\nL 89.920604 170.240555 \r\nL 90.167452 172.862389 \r\nL 90.4143 173.117691 \r\nL 90.661148 171.572566 \r\nL 91.401692 179.786637 \r\nL 91.895388 189.257231 \r\nL 92.142236 191.284104 \r\nL 92.389084 187.370215 \r\nL 92.635932 188.378112 \r\nL 93.129628 192.929151 \r\nL 93.376476 192.00561 \r\nL 93.870173 201.37188 \r\nL 94.363869 196.787541 \r\nL 95.104413 205.716462 \r\nL 95.351261 198.088463 \r\nL 95.598109 194.474276 \r\nL 95.844957 192.742661 \r\nL 96.091805 193.754981 \r\nL 96.832349 187.714318 \r\nL 97.326045 196.880786 \r\nL 97.572893 197.140511 \r\nL 98.066589 191.157559 \r\nL 98.313437 190.777944 \r\nL 98.560285 193.100076 \r\nL 98.807133 188.293734 \r\nL 99.053981 188.602325 \r\nL 99.300829 197.90865 \r\nL 99.794526 201.826984 \r\nL 100.041374 195.795188 \r\nL 100.288222 196.920742 \r\nL 100.53507 193.832682 \r\nL 101.522462 205.561061 \r\nL 102.016158 195.42444 \r\nL 102.263006 195.657542 \r\nL 102.509854 190.105283 \r\nL 102.756702 191.062102 \r\nL 103.00355 188.644514 \r\nL 103.250398 189.268331 \r\nL 103.497246 192.853662 \r\nL 103.744094 188.340367 \r\nL 104.23779 192.300869 \r\nL 104.484638 190.151894 \r\nL 104.731486 186.011558 \r\nL 104.978334 178.503449 \r\nL 105.225182 180.017506 \r\nL 105.472031 183.065589 \r\nL 105.718879 183.043388 \r\nL 105.965727 182.719274 \r\nL 106.212575 181.900078 \r\nL 106.459423 181.671421 \r\nL 106.953119 187.021667 \r\nL 107.199967 187.931875 \r\nL 107.446815 191.47725 \r\nL 107.693663 193.166676 \r\nL 107.940511 197.415802 \r\nL 108.187359 198.701202 \r\nL 108.434207 204.360018 \r\nL 108.681055 202.850405 \r\nL 108.927903 207.552401 \r\nM 109.421599 207.392577 \r\nL 109.668447 201.121023 \r\nL 109.915295 203.172307 \r\nL 110.162143 201.97573 \r\nL 110.655839 192.292002 \r\nL 110.902687 192.780406 \r\nL 111.149536 191.739208 \r\nL 111.643232 200.437239 \r\nL 111.89008 204.970523 \r\nL 112.136928 203.372109 \r\nL 112.383776 205.030468 \r\nL 112.630624 205.78083 \r\nL 112.877472 209.987767 \r\nL 113.12432 211.697181 \r\nL 113.371168 214.756364 \r\nL 113.618016 208.142939 \r\nL 113.864864 206.335835 \r\nL 114.111712 207.217187 \r\nM 114.605408 205.596573 \r\nL 115.345952 211.19991 \r\nM 115.839648 204.939456 \r\nL 116.086496 205.634317 \r\nL 116.333344 205.620984 \r\nL 116.580192 205.436727 \r\nM 117.073889 205.938464 \r\nL 117.320737 201.198723 \r\nL 117.567585 200.692542 \r\nL 117.814433 202.011242 \r\nL 118.061281 200.468328 \r\nL 118.308129 200.11757 \r\nL 118.554977 195.970578 \r\nL 118.801825 196.481182 \r\nL 119.048673 193.701714 \r\nL 119.295521 192.360814 \r\nL 119.542369 192.465159 \r\nL 119.789217 188.864283 \r\nL 120.036065 187.490104 \r\nL 120.282913 185.429909 \r\nL 120.529761 190.642532 \r\nL 120.776609 185.6719 \r\nL 121.270305 182.535017 \r\nL 121.764001 178.461282 \r\nL 122.010849 179.637892 \r\nL 122.504545 176.210173 \r\nL 122.751393 177.575485 \r\nL 122.998242 177.193638 \r\nL 123.24509 176.045905 \r\nL 123.491938 170.899883 \r\nL 123.738786 171.343887 \r\nL 124.232482 167.560987 \r\nL 124.47933 172.080937 \r\nL 124.726178 173.059979 \r\nL 124.973026 175.4576 \r\nL 125.219874 182.03328 \r\nL 125.466722 177.846332 \r\nL 125.71357 177.415639 \r\nL 125.960418 179.433646 \r\nL 126.207266 178.563394 \r\nM 126.700962 182.071024 \r\nL 126.94781 184.644035 \r\nL 127.194658 184.730603 \r\nL 127.441506 179.708937 \r\nL 127.688354 178.554527 \r\nL 127.935202 175.448711 \r\nL 128.18205 173.921342 \r\nL 128.675747 180.403798 \r\nL 128.922595 183.105566 \r\nL 129.169443 182.315226 \r\nL 129.416291 178.314747 \r\nL 129.663139 184.3754 \r\nL 129.909987 182.166481 \r\nL 130.156835 186.337906 \r\nL 130.403683 183.722727 \r\nL 130.650531 185.871702 \r\nL 130.897379 186.577663 \r\nL 131.144227 181.396151 \r\nL 131.391075 180.403798 \r\nL 131.637923 178.601138 \r\nL 131.884771 180.181797 \r\nL 132.131619 184.111231 \r\nL 132.378467 183.702738 \r\nL 132.625315 184.446445 \r\nL 132.872163 182.226426 \r\nL 133.119011 185.307808 \r\nL 133.365859 184.475301 \r\nL 133.612707 181.655876 \r\nL 133.859555 181.198561 \r\nL 134.106403 179.759993 \r\nL 134.353251 181.60482 \r\nL 134.6001 185.611955 \r\nL 134.846948 184.632935 \r\nL 135.340644 186.127004 \r\nL 135.587492 186.055959 \r\nL 135.83434 183.500725 \r\nL 136.081188 183.900329 \r\nL 136.328036 186.153648 \r\nL 136.574884 190.662499 \r\nL 136.821732 189.450377 \r\nL 137.06858 194.520888 \r\nL 137.315428 195.637575 \r\nL 137.562276 196.041601 \r\nL 138.055972 198.612401 \r\nL 138.30282 197.058387 \r\nL 138.549668 200.812431 \r\nL 138.796516 200.281838 \r\nL 139.043364 199.33833 \r\nM 139.53706 200.71253 \r\nL 139.783908 201.815884 \r\nL 140.030756 198.008551 \r\nL 140.277605 198.052952 \r\nL 140.524453 195.155826 \r\nL 140.771301 194.958236 \r\nL 141.264997 197.882006 \r\nL 141.511845 201.551693 \r\nL 141.758693 201.260879 \r\nL 142.005541 200.588218 \r\nL 142.252389 194.647433 \r\nL 142.499237 192.314202 \r\nL 142.746085 191.483906 \r\nL 142.992933 192.116611 \r\nL 143.239781 189.372676 \r\nL 143.486629 189.126241 \r\nL 143.733477 192.087756 \r\nL 143.980325 188.344812 \r\nL 144.227173 191.665952 \r\nL 144.474021 189.907692 \r\nL 144.720869 189.166219 \r\nL 144.967717 187.192613 \r\nL 145.214565 188.034009 \r\nL 145.461413 189.428177 \r\nL 145.708261 189.155119 \r\nL 145.955109 188.218266 \r\nL 146.201958 187.896363 \r\nL 146.448806 182.135413 \r\nL 146.695654 182.148725 \r\nL 146.942502 181.733577 \r\nL 147.18935 181.085349 \r\nL 147.436198 179.986439 \r\nL 147.683046 180.445966 \r\nL 147.929894 182.301915 \r\nL 148.176742 179.184999 \r\nL 148.42359 180.918847 \r\nL 148.670438 184.073486 \r\nL 148.917286 184.428689 \r\nL 149.164134 185.760701 \r\nL 149.410982 185.956058 \r\nL 149.904678 183.742694 \r\nL 150.151526 185.412153 \r\nL 150.398374 189.281642 \r\nL 150.645222 188.826539 \r\nL 150.89207 189.65239 \r\nL 151.138918 192.60946 \r\nL 151.385766 190.085294 \r\nL 151.632614 185.647488 \r\nL 151.879463 184.350988 \r\nL 152.126311 183.840384 \r\nL 152.620007 184.941505 \r\nL 153.113703 179.569058 \r\nL 153.360551 179.511346 \r\nL 153.607399 180.179563 \r\nL 153.854247 180.292797 \r\nL 154.347943 177.630986 \r\nL 154.594791 178.403548 \r\nL 154.841639 178.254824 \r\nL 155.088487 175.826114 \r\nL 155.335335 176.187973 \r\nL 155.582183 176.076972 \r\nL 156.075879 178.967442 \r\nM 156.569575 181.740254 \r\nL 156.816423 180.530344 \r\nL 157.063271 183.041177 \r\nL 157.310119 183.252079 \r\nL 157.556967 182.352971 \r\nL 157.803816 184.497501 \r\nL 158.050664 183.933629 \r\nL 158.297512 179.3293 \r\nM 158.791208 178.381348 \r\nL 159.038056 177.202526 \r\nL 159.284904 175.38211 \r\nL 159.531752 175.188964 \r\nL 159.7786 168.870798 \r\nL 160.025448 167.434442 \r\nL 160.272296 167.876234 \r\nL 160.519144 169.909763 \r\nL 160.765992 163.831355 \r\nL 161.01284 164.788174 \r\nL 161.259688 164.597261 \r\nL 161.753384 165.680626 \r\nL 162.000232 163.291894 \r\nL 162.493928 162.050895 \r\nL 162.740776 159.548929 \r\nL 162.987624 161.3538 \r\nL 163.234472 164.504016 \r\nL 163.481321 163.234161 \r\nL 163.728169 165.56297 \r\nL 163.975017 163.080992 \r\nL 164.221865 164.501805 \r\nL 164.468713 164.004512 \r\nL 164.715561 165.747227 \r\nL 164.962409 165.203322 \r\nL 165.209257 162.608111 \r\nL 165.456105 164.137713 \r\nL 165.702953 162.676945 \r\nL 165.949801 163.820254 \r\nL 166.196649 163.203093 \r\nL 166.443497 164.965776 \r\nL 166.690345 167.971691 \r\nL 167.184041 165.878217 \r\nL 167.430889 163.540519 \r\nL 167.677737 163.251917 \r\nL 167.924585 162.355042 \r\nL 168.171433 160.769939 \r\nL 168.418281 161.717892 \r\nL 168.665129 164.048912 \r\nM 169.158825 164.162124 \r\nL 169.652522 169.030644 \r\nL 169.89937 169.148301 \r\nL 170.146218 169.141645 \r\nL 170.393066 167.221328 \r\nL 170.639914 166.646335 \r\nL 170.886762 166.697391 \r\nL 171.13361 166.284476 \r\nL 171.874154 155.452993 \r\nL 172.121002 155.848152 \r\nL 172.861546 153.186362 \r\nL 173.108394 154.229771 \r\nL 173.355242 154.163171 \r\nL 173.848938 155.091134 \r\nL 174.095786 156.711748 \r\nL 174.342634 155.464093 \r\nL 174.589482 156.42759 \r\nL 175.083179 153.244074 \r\nL 175.330027 153.830168 \r\nL 175.576875 156.880461 \r\nL 175.823723 156.523047 \r\nL 176.070571 154.309683 \r\nL 176.317419 155.885897 \r\nL 176.564267 154.187582 \r\nL 176.811115 154.331883 \r\nM 177.304811 150.417994 \r\nL 177.551659 149.696488 \r\nL 177.798507 149.401229 \r\nL 178.045355 150.63334 \r\nL 178.292203 150.042802 \r\nL 178.539051 151.383702 \r\nL 178.785899 151.510248 \r\nL 179.032747 152.280599 \r\nL 179.279595 149.050471 \r\nL 179.526443 147.605225 \r\nL 179.773291 150.036146 \r\nL 180.266987 147.258911 \r\nL 180.513835 146.464148 \r\nL 180.760683 147.964872 \r\nL 181.007532 147.707359 \r\nL 181.25438 149.259139 \r\nL 181.501228 146.803807 \r\nL 181.748076 146.797151 \r\nL 181.994924 147.902716 \r\nL 182.241772 147.64297 \r\nL 182.48862 148.575378 \r\nL 182.735468 150.167136 \r\nL 182.982316 150.684396 \r\nL 183.229164 152.031952 \r\nL 183.476012 151.929818 \r\nL 183.72286 152.835603 \r\nL 183.969708 154.402928 \r\nL 184.216556 154.653786 \r\nL 184.463404 153.559321 \r\nL 184.710252 153.095328 \r\nL 184.9571 154.693742 \r\nL 185.203948 155.117779 \r\nL 185.450796 154.638242 \r\nL 185.697644 152.795626 \r\nL 185.944492 152.646902 \r\nL 186.19134 156.678448 \r\nL 186.438188 156.765038 \r\nL 186.685036 156.567447 \r\nL 186.931885 160.714439 \r\nL 187.178733 159.136014 \r\nL 187.425581 163.746998 \r\nL 187.672429 162.563711 \r\nL 187.919277 163.505007 \r\nL 188.166125 159.697674 \r\nL 188.659821 156.187833 \r\nL 188.906669 152.529223 \r\nL 189.153517 152.677969 \r\nL 189.400365 153.93228 \r\nL 189.647213 156.72506 \r\nL 189.894061 154.160938 \r\nL 190.387757 157.433255 \r\nL 190.881453 163.687053 \r\nL 191.128301 165.269923 \r\nL 191.375149 165.598481 \r\nL 191.621997 166.375488 \r\nL 191.868845 166.031385 \r\nL 192.115693 164.213202 \r\nL 192.362541 163.243049 \r\nL 192.60939 161.302744 \r\nL 193.349934 169.954163 \r\nL 193.596782 170.411479 \r\nL 193.84363 172.536041 \r\nL 194.337326 168.144848 \r\nL 194.584174 171.050862 \r\nL 194.831022 169.281502 \r\nL 195.07787 163.929022 \r\nL 195.324718 163.940123 \r\nL 195.571566 159.74873 \r\nL 195.818414 157.470999 \r\nL 196.065262 157.359998 \r\nL 196.31211 153.834612 \r\nL 196.558958 155.825952 \r\nL 197.052654 153.217429 \r\nL 197.299502 150.147147 \r\nL 197.54635 152.604713 \r\nL 197.793198 151.403691 \r\nL 198.040046 148.184663 \r\nL 198.286894 147.041353 \r\nL 198.533743 147.891616 \r\nL 198.780591 145.911355 \r\nL 199.027439 150.98631 \r\nL 199.274287 150.322537 \r\nL 199.521135 143.602535 \r\nL 200.014831 141.802108 \r\nL 200.755375 145.922455 \r\nL 201.002223 151.581293 \r\nL 201.249071 150.848686 \r\nL 201.495919 146.426403 \r\nL 201.742767 145.178748 \r\nL 201.989615 145.48734 \r\nL 202.236463 144.610432 \r\nL 202.483311 150.742108 \r\nL 202.730159 152.813403 \r\nL 202.977007 153.694734 \r\nL 203.223855 153.499376 \r\nL 203.470703 153.608166 \r\nL 203.717551 155.401937 \r\nL 203.964399 155.535138 \r\nL 204.211248 159.495661 \r\nL 204.458096 160.765495 \r\nL 204.704944 163.478363 \r\nL 204.951792 158.625409 \r\nL 205.19864 156.776138 \r\nL 205.445488 158.394519 \r\nL 205.692336 158.01046 \r\nL 205.939184 165.396468 \r\nL 206.186032 164.874764 \r\nL 206.43288 168.311349 \r\nL 206.679728 167.474398 \r\nL 206.926576 168.380161 \r\nL 207.173424 164.222069 \r\nL 207.420272 157.124663 \r\nL 207.66712 154.609386 \r\nL 207.913968 156.443135 \r\nL 208.160816 160.290424 \r\nL 208.407664 157.357765 \r\nL 208.654512 155.983586 \r\nL 208.90136 158.485552 \r\nL 209.148208 156.378746 \r\nL 209.395056 158.256873 \r\nL 209.888752 149.718688 \r\nL 210.135601 148.750768 \r\nL 210.382449 152.105208 \r\nL 210.629297 151.30379 \r\nL 210.876145 148.428865 \r\nL 211.122993 148.821791 \r\nL 211.369841 148.706368 \r\nL 211.616689 146.66395 \r\nL 212.110385 154.225327 \r\nL 212.357233 155.171046 \r\nL 213.097777 161.573591 \r\nL 213.344625 162.201852 \r\nL 213.591473 164.41966 \r\nL 213.838321 164.086657 \r\nL 214.085169 170.442568 \r\nL 214.332017 171.470432 \r\nL 214.825713 167.327885 \r\nL 215.072561 163.469496 \r\nL 215.319409 161.560279 \r\nL 215.566257 171.969937 \r\nL 215.813106 176.103617 \r\nL 216.059954 176.694133 \r\nL 216.306802 181.085349 \r\nL 216.800498 173.572795 \r\nL 217.047346 173.361893 \r\nL 217.294194 181.755777 \r\nL 217.541042 181.864567 \r\nL 217.78789 176.356708 \r\nL 218.281586 170.065164 \r\nL 218.528434 179.358156 \r\nL 219.268978 164.308659 \r\nL 219.515826 154.702631 \r\nL 219.762674 153.974469 \r\nL 220.009522 156.74726 \r\nL 220.25637 156.751704 \r\nL 220.503218 157.197941 \r\nL 220.750066 156.76946 \r\nL 220.996914 154.582741 \r\nL 221.243762 144.987835 \r\nL 221.737459 155.013434 \r\nL 221.984307 154.893544 \r\nL 222.231155 155.719395 \r\nL 222.478003 155.346437 \r\nL 222.724851 157.524267 \r\nL 222.971699 161.871082 \r\nL 223.218547 159.884165 \r\nL 223.465395 154.127637 \r\nL 223.959091 154.285272 \r\nL 224.205939 153.297363 \r\nL 224.452787 149.7875 \r\nL 224.699635 149.188094 \r\nL 224.946483 145.846965 \r\nL 225.193331 145.114359 \r\nL 225.440179 146.164446 \r\nL 225.687027 148.082529 \r\nL 225.933875 141.711074 \r\nL 226.180723 141.018424 \r\nL 226.427571 141.113902 \r\nL 226.921267 142.821083 \r\nL 227.168115 143.68468 \r\nL 227.414964 145.629408 \r\nL 227.661812 140.31025 \r\nL 227.90866 138.942706 \r\nL 228.155508 136.83592 \r\nL 228.402356 136.478484 \r\nL 228.896052 140.565553 \r\nL 229.1429 141.804319 \r\nL 229.636596 146.619549 \r\nL 229.883444 149.316873 \r\nL 230.130292 150.580051 \r\nL 230.37714 147.625214 \r\nL 230.623988 141.726618 \r\nL 230.870836 141.089468 \r\nL 231.117684 144.661488 \r\nL 231.364532 150.16048 \r\nL 231.61138 150.320304 \r\nL 231.858228 144.996702 \r\nL 232.105076 147.494224 \r\nL 232.351924 147.583025 \r\nL 232.598772 146.040111 \r\nL 232.84562 142.299379 \r\nL 233.092468 140.445663 \r\nL 233.339317 141.156069 \r\nL 233.586165 142.972041 \r\nL 233.833013 139.413354 \r\nL 234.079861 138.578635 \r\nL 234.326709 133.960995 \r\nL 234.820405 136.447417 \r\nL 235.314101 142.641271 \r\nL 235.807797 143.944426 \r\nL 236.054645 140.476752 \r\nL 236.301493 142.718971 \r\nL 236.548341 137.941485 \r\nL 236.795189 137.486382 \r\nL 237.042037 138.201232 \r\nL 237.288885 137.735028 \r\nL 237.535733 136.185459 \r\nL 237.782581 137.193335 \r\nL 238.029429 136.620574 \r\nM 238.523125 140.29915 \r\nL 238.769973 140.743154 \r\nL 239.016821 141.617829 \r\nL 239.26367 142.914329 \r\nL 239.510518 142.36598 \r\nL 239.757366 142.643482 \r\nL 240.004214 142.505836 \r\nL 240.251062 138.008086 \r\nL 240.49791 139.380054 \r\nL 240.744758 135.870212 \r\nL 240.991606 135.959013 \r\nL 241.238454 138.500935 \r\nL 241.485302 136.622785 \r\nL 241.73215 136.185459 \r\nL 241.978998 135.068772 \r\nL 242.225846 134.771302 \r\nL 242.472694 138.274488 \r\nL 242.719542 144.086494 \r\nL 243.213238 144.779145 \r\nL 243.460086 146.845974 \r\nL 243.706934 146.144457 \r\nL 243.953782 150.038379 \r\nL 244.20063 150.078335 \r\nL 244.941175 147.312178 \r\nL 245.188023 147.745082 \r\nL 245.434871 147.334378 \r\nL 245.681719 146.388659 \r\nL 245.928567 150.069446 \r\nL 246.175415 147.971528 \r\nM 246.669111 144.474998 \r\nL 246.915959 143.336132 \r\nL 247.162807 146.057867 \r\nL 247.409655 143.216243 \r\nL 247.656503 141.855375 \r\nL 247.903351 141.236003 \r\nL 248.397047 137.821596 \r\nL 248.643895 140.285817 \r\nL 248.890743 136.889188 \r\nL 249.137591 135.526109 \r\nL 249.384439 132.307081 \r\nL 249.631287 126.734833 \r\nL 249.878135 126.264184 \r\nL 250.124983 127.389738 \r\nL 250.371831 127.167736 \r\nL 250.618679 128.224457 \r\nL 251.359224 126.850278 \r\nL 251.606072 128.668461 \r\nL 251.85292 128.220012 \r\nM 252.346616 124.210666 \r\nL 252.593464 123.933164 \r\nL 252.840312 123.415904 \r\nL 253.580856 118.851531 \r\nL 253.827704 118.103402 \r\nL 254.074552 116.70479 \r\nL 254.3214 117.435163 \r\nL 254.568248 119.288879 \r\nL 254.815096 119.257812 \r\nL 255.061944 114.766696 \r\nL 255.308792 114.757829 \r\nL 255.55564 115.650281 \r\nL 256.049336 120.13472 \r\nL 256.296184 115.512635 \r\nL 256.543033 113.81432 \r\nL 256.789881 113.916433 \r\nL 257.036729 112.786456 \r\nM 257.530425 115.36389 \r\nL 257.777273 116.318498 \r\nL 258.024121 118.360916 \r\nL 258.270969 119.197867 \r\nL 258.517817 119.268912 \r\nL 258.764665 119.066877 \r\nL 259.011513 118.358704 \r\nL 259.258361 121.144828 \r\nL 259.505209 120.820693 \r\nL 259.998905 105.0852 \r\nL 260.245753 100.889364 \r\nL 260.492601 100.889364 \r\nL 260.739449 100.250003 \r\nL 261.233145 94.016193 \r\nL 261.479993 93.4856 \r\nL 261.726841 94.489053 \r\nL 261.973689 93.445644 \r\nL 262.220537 89.41852 \r\nL 262.467386 89.775956 \r\nL 262.714234 91.598583 \r\nL 262.961082 91.081323 \r\nL 263.20793 95.254959 \r\nL 263.454778 95.508028 \r\nL 263.701626 89.622766 \r\nL 263.948474 87.254001 \r\nL 264.195322 87.857851 \r\nL 264.44217 84.667679 \r\nL 264.935866 76.653409 \r\nL 265.182714 76.573497 \r\nL 265.429562 77.88552 \r\nL 265.67641 76.8621 \r\nL 265.923258 81.648452 \r\nL 266.170106 82.028089 \r\nL 266.416954 77.670174 \r\nL 266.663802 80.933602 \r\nL 266.91065 81.710609 \r\nL 267.404346 83.812971 \r\nL 267.651194 79.956793 \r\nL 267.898042 80.442986 \r\nL 268.144891 83.819627 \r\nL 268.391739 83.126998 \r\nL 268.638587 78.573726 \r\nL 268.885435 77.536972 \r\nL 269.132283 73.520971 \r\nL 269.379131 73.980519 \r\nL 269.872827 70.768147 \r\nL 270.119675 78.047577 \r\nL 270.366523 79.74368 \r\nL 270.613371 80.509587 \r\nL 270.860219 85.311484 \r\nL 271.107067 85.553475 \r\nL 271.847611 77.28167 \r\nL 272.341307 75.339153 \r\nL 272.588155 71.625065 \r\nL 273.081851 68.838941 \r\nL 273.575547 72.475329 \r\nL 273.822395 70.579445 \r\nL 274.069244 73.691916 \r\nL 274.316092 78.962229 \r\nL 274.809788 72.570807 \r\nL 275.056636 75.878635 \r\nL 275.303484 76.890956 \r\nL 275.550332 80.474075 \r\nL 275.79718 77.925476 \r\nL 276.044028 73.436614 \r\nL 276.290876 72.881609 \r\nL 276.537724 70.566112 \r\nL 276.784572 66.900869 \r\nL 277.03142 65.86856 \r\nL 277.278268 66.854257 \r\nL 277.771964 65.171465 \r\nL 278.018812 65.477845 \r\nL 278.26566 65.546657 \r\nL 278.759356 63.344394 \r\nL 279.253052 57.630077 \r\nL 279.4999 56.229232 \r\nL 279.746749 57.057295 \r\nL 279.993597 57.461343 \r\nL 280.240445 53.596298 \r\nL 280.487293 54.526473 \r\nL 280.734141 57.13944 \r\nL 280.980989 57.512399 \r\nL 281.227837 56.63328 \r\nL 281.474685 59.452704 \r\nL 281.721533 64.296791 \r\nL 281.968381 62.40533 \r\nL 282.215229 56.222576 \r\nL 282.462077 55.925085 \r\nL 282.708925 54.821753 \r\nL 282.955773 60.538302 \r\nL 283.202621 61.210964 \r\nL 283.449469 65.23141 \r\nL 283.696317 62.700588 \r\nL 283.943165 63.142381 \r\nL 284.190013 62.880423 \r\nL 284.436861 63.73513 \r\nL 284.683709 67.871022 \r\nL 284.930557 68.301692 \r\nL 285.177405 63.069124 \r\nL 285.424253 67.535786 \r\nL 285.671102 66.456865 \r\nL 285.91795 67.355973 \r\nM 286.411646 72.497529 \r\nL 286.658494 71.098917 \r\nL 286.905342 66.672211 \r\nL 287.399038 61.499566 \r\nL 287.645886 61.686035 \r\nL 287.892734 60.092065 \r\nL 288.38643 53.804966 \r\nL 288.633278 47.011708 \r\nL 288.880126 46.925118 \r\nL 289.126974 46.296879 \r\nL 289.373822 46.35459 \r\nL 289.62067 46.032688 \r\nL 290.114366 44.298861 \r\nL 290.361214 45.42886 \r\nL 290.85491 42.192054 \r\nL 291.101758 42.407379 \r\nL 291.348607 44.343262 \r\nL 291.595455 43.472988 \r\nL 292.089151 37.778639 \r\nL 292.335999 40.755719 \r\nL 292.829695 39.374841 \r\nL 293.076543 35.198994 \r\nL 293.570239 38.020629 \r\nL 293.817087 37.445636 \r\nL 294.063935 36.257925 \r\nL 294.310783 37.416802 \r\nL 294.804479 46.1903 \r\nL 295.051327 45.526506 \r\nL 295.545023 51.367411 \r\nL 295.791871 51.567213 \r\nL 296.038719 58.31605 \r\nL 296.285567 59.994398 \r\nL 296.532415 54.244548 \r\nL 296.779263 51.318545 \r\nL 297.026111 46.931795 \r\nL 297.27296 49.462617 \r\nL 297.519808 53.587409 \r\nL 297.766656 52.406354 \r\nL 298.013504 50.381714 \r\nL 298.260352 50.295125 \r\nL 298.5072 48.765523 \r\nM 299.000896 43.759379 \r\nL 299.247744 44.516397 \r\nL 299.494592 55.663127 \r\nL 299.74144 56.784237 \r\nL 299.988288 50.901207 \r\nL 300.481984 46.976196 \r\nL 300.97568 48.994202 \r\nL 301.222528 39.377053 \r\nL 301.469376 38.504611 \r\nL 301.716224 36.866219 \r\nL 301.963072 30.43263 \r\nL 302.456768 27.51105 \r\nL 302.950464 20.890969 \r\nL 303.197313 20.722257 \r\nL 303.444161 19.032831 \r\nL 303.691009 25.402031 \r\nL 303.937857 25.912636 \r\nL 304.431553 29.184953 \r\nL 304.678401 29.717757 \r\nL 304.925249 31.966654 \r\nL 305.172097 37.947395 \r\nL 305.418945 36.206891 \r\nL 305.912641 29.724435 \r\nL 306.159489 25.55301 \r\nL 306.406337 25.382086 \r\nL 306.653185 22.729163 \r\nL 306.900033 21.565864 \r\nL 307.393729 27.797441 \r\nL 307.887425 27.251325 \r\nL 308.134273 30.954334 \r\nL 308.381121 23.816972 \r\nM 308.874818 18.837452 \r\nL 309.121666 17.083636 \r\nL 309.368514 20.351487 \r\nL 309.615362 19.681059 \r\nL 309.86221 27.717529 \r\nL 310.109058 29.702235 \r\nL 310.355906 30.239462 \r\nL 310.602754 26.862821 \r\nL 310.849602 32.557171 \r\nL 311.09645 33.205399 \r\nL 311.343298 29.20273 \r\nL 311.836994 33.138798 \r\nL 312.083842 35.969323 \r\nL 312.33069 36.857331 \r\nL 312.824386 37.749804 \r\nL 313.071234 46.125911 \r\nL 313.318082 46.159211 \r\nL 313.56493 39.459219 \r\nL 313.811778 39.516931 \r\nL 314.305474 32.017689 \r\nL 314.552322 31.999955 \r\nL 315.046019 26.760709 \r\nL 315.292867 26.669697 \r\nL 315.539715 24.287599 \r\nM 316.033411 29.939759 \r\nL 316.280259 34.410887 \r\nL 316.527107 41.421725 \r\nL 316.773955 44.545275 \r\nL 317.020803 42.238666 \r\nL 317.267651 43.632855 \r\nL 317.761347 51.824727 \r\nL 318.008195 48.636788 \r\nL 318.501891 53.25885 \r\nL 318.748739 46.578804 \r\nL 318.995587 46.896284 \r\nL 319.242435 57.010683 \r\nL 319.489283 58.773387 \r\nL 319.982979 46.876295 \r\nL 320.229827 55.680883 \r\nL 320.476676 50.863441 \r\nL 320.723524 51.362945 \r\nL 320.970372 49.669097 \r\nL 321.21722 44.727299 \r\nL 321.464068 45.082502 \r\nL 321.710916 42.525057 \r\nL 321.957764 42.624958 \r\nL 322.204612 40.939955 \r\nL 322.45146 44.878278 \r\nL 322.698308 46.250267 \r\nL 322.945156 46.461169 \r\nL 323.192004 47.153797 \r\nL 323.438852 42.063276 \r\nL 323.6857 42.074376 \r\nL 323.932548 50.819041 \r\nL 324.179396 55.319024 \r\nL 324.426244 55.516614 \r\nL 324.673092 56.224787 \r\nL 324.91994 59.357248 \r\nL 325.166788 60.322956 \r\nL 325.413636 55.791884 \r\nL 325.660484 62.855989 \r\nL 325.907332 62.076771 \r\nL 326.401029 59.217391 \r\nL 326.647877 57.252674 \r\nL 327.388421 45.639762 \r\nL 327.635269 44.376562 \r\nL 327.882117 45.295659 \r\nL 328.128965 43.646167 \r\nL 328.375813 44.396551 \r\nL 328.622661 47.18042 \r\nL 328.869509 44.955978 \r\nL 329.116357 41.201934 \r\nL 329.363205 41.563772 \r\nL 329.856901 38.133842 \r\nL 330.103749 38.637812 \r\nL 330.350597 45.197969 \r\nL 330.597445 46.729782 \r\nL 330.844293 45.30897 \r\nL 331.091141 40.908866 \r\nL 331.337989 41.155323 \r\nL 331.831685 34.319875 \r\nL 332.078534 34.239963 \r\nL 332.325382 34.524099 \r\nL 332.57223 37.809728 \r\nL 332.819078 33.189876 \r\nL 333.065926 35.130182 \r\nL 333.312774 38.160508 \r\nL 333.559622 45.288981 \r\nL 333.80647 46.35459 \r\nL 334.300166 42.589446 \r\nL 334.547014 37.658792 \r\nL 334.793862 37.2059 \r\nL 335.04071 38.366944 \r\nL 335.287558 36.100313 \r\nL 335.534406 35.181216 \r\nL 335.781254 36.24908 \r\nL 336.028102 37.980695 \r\nL 336.27495 40.78902 \r\nL 336.521798 45.801797 \r\nL 336.768646 45.517661 \r\nL 337.015494 38.293709 \r\nL 337.262342 40.125225 \r\nL 337.50919 40.602529 \r\nL 337.756038 39.332652 \r\nL 338.249735 47.999616 \r\nL 338.496583 69.797994 \r\nL 338.743431 66.614478 \r\nL 338.990279 70.559456 \r\nL 339.237127 63.584151 \r\nL 339.483975 61.230931 \r\nL 339.730823 62.59182 \r\nL 339.977671 70.825859 \r\nL 340.224519 73.882829 \r\nL 340.471367 69.176389 \r\nL 340.965063 80.906979 \r\nL 341.458759 69.371746 \r\nL 341.705607 70.725958 \r\nL 341.952455 70.67269 \r\nL 342.199303 66.98967 \r\nL 342.446151 68.905542 \r\nL 342.939847 62.121172 \r\nL 343.186695 62.334285 \r\nL 343.433543 69.664793 \r\nL 343.92724 67.156171 \r\nL 344.174088 70.38851 \r\nL 344.420936 68.275069 \r\nL 344.667784 63.586384 \r\nL 344.914632 63.497584 \r\nL 345.16148 56.020563 \r\nL 345.655176 53.440896 \r\nL 345.902024 55.574326 \r\nL 346.148872 52.894759 \r\nL 346.39572 54.941621 \r\nL 346.642568 55.469981 \r\nL 346.889416 56.526723 \r\nL 347.383112 50.743551 \r\nL 347.62996 49.105203 \r\nL 348.123656 50.141935 \r\nL 348.370504 48.199418 \r\nL 348.8642 50.976653 \r\nL 349.604745 58.395984 \r\nL 349.851593 59.061989 \r\nL 350.098441 58.622408 \r\nL 350.345289 59.532616 \r\nL 350.592137 63.295549 \r\nL 350.838985 63.346627 \r\nL 351.085833 65.082664 \r\nL 351.332681 70.936859 \r\nL 351.579529 71.873712 \r\nL 352.073225 68.530372 \r\nL 352.320073 73.225712 \r\nL 352.566921 68.299481 \r\nL 352.813769 67.686764 \r\nL 353.060617 68.010878 \r\nL 353.307465 68.794541 \r\nL 353.801161 63.861654 \r\nL 354.048009 64.192445 \r\nL 354.294857 63.319982 \r\nL 354.541705 64.365602 \r\nL 355.035401 71.001249 \r\nL 355.28225 71.733855 \r\nL 355.775946 78.52267 \r\nL 356.022794 75.379131 \r\nL 356.269642 78.613682 \r\nL 356.763338 74.59768 \r\nL 357.010186 72.377661 \r\nL 357.257034 68.228436 \r\nL 357.503882 71.887023 \r\nL 357.75073 68.667995 \r\nL 357.997578 70.814758 \r\nL 358.244426 67.269383 \r\nL 358.491274 67.486963 \r\nL 358.738122 64.640894 \r\nL 358.98497 64.472159 \r\nL 359.231818 65.92406 \r\nL 359.231818 65.92406 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 39.65 224.64 \r\nL 39.65 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 374.45 224.64 \r\nL 374.45 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 39.65 224.64 \r\nL 374.45 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 39.65 7.2 \r\nL 374.45 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p4b58569966\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       6157.600098\n",
       "1       6146.350098\n",
       "2       6079.799805\n",
       "3       6048.250000\n",
       "4       5904.600098\n",
       "           ...     \n",
       "1229    7865.950195\n",
       "1230    7861.049805\n",
       "1231    7925.149902\n",
       "1232    7928.950195\n",
       "1233    7896.250000\n",
       "Name: Close, Length: 1234, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import numpy as np\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "#print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + Splitting the data into Training/Test sets\n",
    "\n",
    "training_size=int(len(df1)*0.65)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(802, 432)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "training_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(701, 100)\n(701,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.35986792]\n [0.34491968]\n [0.3378331 ]\n [0.30556709]\n [0.27372782]\n [0.27176244]\n [0.29627921]\n [0.27126824]\n [0.24940188]\n [0.24944685]\n [0.26501267]\n [0.25760035]\n [0.26221627]\n [0.25882455]\n [0.26932533]\n [0.25678053]\n [0.23811495]\n [0.21741664]\n [0.21601279]\n [0.19608945]\n [0.19941372]\n [0.22069605]\n [0.1912714 ]\n [0.19132756]\n [0.17258334]\n [0.15933101]\n [0.15309793]\n [0.17201061]\n [0.20480449]\n [0.21041988]\n [0.21057716]\n [0.22512102]\n [0.20546715]\n [0.21886545]\n [0.20776946]\n [0.20061543]\n [0.16138633]\n [0.1705618 ]\n [0.17723292]\n [0.21969647]\n [0.22281871]\n [0.22339144]\n [0.20641047]\n [0.21935954]\n [0.22165067]\n [0.21342971]\n [0.20243484]\n [0.22176297]\n [0.20337816]\n [0.21719202]\n [0.20270432]\n [0.18631867]\n [0.18430832]\n [0.19533697]\n [0.21025142]\n [0.21971895]\n [0.24933454]\n [0.25674686]\n [0.26777551]\n [0.27929825]\n [0.28965305]\n [0.28792347]\n [0.30643188]\n [0.30679118]\n [0.30268076]\n [0.30132188]\n [0.29150613]\n [0.27886031]\n [0.30711692]\n [0.28758654]\n [0.26614705]\n [0.2687638 ]\n [0.29367365]\n [0.30109726]\n [0.29880614]\n [0.29743596]\n [0.28968672]\n [0.27880416]\n [0.27072918]\n [0.25990267]\n [0.22934375]\n [0.22303203]\n [0.20566929]\n [0.2262441 ]\n [0.22616546]\n [0.22395298]\n [0.22929878]\n [0.21157663]\n [0.22473913]\n [0.21446297]\n [0.20097484]\n [0.19685312]\n [0.19853774]\n [0.2116216 ]\n [0.18920489]\n [0.19106927]\n [0.18075943]\n [0.19500004]\n [0.20931929]\n [0.20864544]]\n"
     ]
    }
   ],
   "source": [
    "nt(X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(331, 100)\n(331,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "print(X_test.shape), print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_10/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-458e9b85b343>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    211\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    651\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    652\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2516\u001b[1;33m     return list(_generate_zero_filled_state_for_cell(\n\u001b[0m\u001b[0;32m   2517\u001b[0m         self, inputs, batch_size, dtype))\n\u001b[0;32m   2518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2996\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2998\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3014\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3015\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3016\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   3009\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3011\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2911\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2912\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2958\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2960\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2961\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2896\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2897\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3028\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m     \"\"\"\n\u001b[1;32m-> 3030\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[0;32m   3031\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   3032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    868\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_10/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(100, 1)))\n",
    "model.add(keras.layers.LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\soume\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2475\u001b[0m     \"\"\"\n\u001b[0;32m   2476\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2477\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2478\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-82657f88da1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\soume\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\soume\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2691\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2693\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2694\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformback to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Data RMSE\n",
    "math.sqrt(mean_squared_error(ytest,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting \n",
    "# shift train predictions for plotting\n",
    "look_back=100\n",
    "trainPredictPlot = numpy.empty_like(df1)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(df1)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df1))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd00b2a4e6109be04e8abf0f9efc38ba5b621e882d67e3744bb7ddf65a525621121",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "0b2a4e6109be04e8abf0f9efc38ba5b621e882d67e3744bb7ddf65a525621121"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}